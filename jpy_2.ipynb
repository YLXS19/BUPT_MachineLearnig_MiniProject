{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2FeatureExtractor, Wav2Vec2Processor, BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader  # 确保导入 DataLoader\n",
    "import librosa\n",
    "\n",
    "# 检查是否能够使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at ./wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at ./wav2vec2-xls-r-300m and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded successfully.\n",
      "    filename Language  Story_type\n",
      "0  00001.wav  Chinese  True Story\n",
      "1  00002.wav  Chinese  True Story\n",
      "2  00003.wav  Chinese  True Story\n",
      "3  00004.wav  Chinese  True Story\n",
      "4  00005.wav  Chinese  True Story\n"
     ]
    }
   ],
   "source": [
    "# 加载模型（一次加载）\n",
    "model_english = Wav2Vec2ForCTC.from_pretrained(\"./wav2vec2-base-960h\").to(device)\n",
    "processor_english = Wav2Vec2Processor.from_pretrained(\"./wav2vec2-base-960h\")\n",
    "model_chinese = Wav2Vec2ForCTC.from_pretrained(\"./wav2vec2-large-xlsr-53-chinese-zh-cn\").to(device)\n",
    "processor_chinese = Wav2Vec2Processor.from_pretrained(\"./wav2vec2-large-xlsr-53-chinese-zh-cn\")\n",
    "\n",
    "_model = Wav2Vec2ForCTC.from_pretrained(\"./wav2vec2-xls-r-300m\").to(device)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"./wav2vec2-xls-r-300m\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./bert-base-multilingual-cased\")\n",
    "bert_model = BertModel.from_pretrained(\"./bert-base-multilingual-cased\").to(device)\n",
    "\n",
    "# 读取CSV文件\n",
    "attributes_file = \"CBU0521DD_stories_attributes.csv\"\n",
    "df = pd.read_csv(attributes_file)\n",
    "print(\"Dataframe loaded successfully.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 定义函数来提取音频特征\n",
    "def extract_audio_features(waveform, model, processor):\n",
    "    inputs = processor(waveform, return_tensors=\"pt\", sampling_rate=16000, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # 获取模型的logits输出\n",
    "    # 压平，忽略 batch_size 维度\n",
    "    return logits.flatten(start_dim=1).cpu().numpy()  # 如果需要保存为numpy数组，可以进行转换\n",
    "\n",
    "# 定义函数来转录音频文本\n",
    "def transcribe_audio(waveform, model, processor):\n",
    "    inputs = processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    # 获取预测的ID\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    # 使用分词器将预测的ID转换为文本\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    return transcription[0]\n",
    "\n",
    "# 定义函数来提取文本特征\n",
    "def extract_text_features(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 创建数据集类\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, dataframe, audio_dir):\n",
    "        self.dataframe = dataframe\n",
    "        self.audio_dir = audio_dir\n",
    "        self.count = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        file_name = row['filename']\n",
    "        language = row['Language']\n",
    "        story_type = row['Story_type']\n",
    "        file_path = os.path.join(self.audio_dir, file_name)\n",
    "\n",
    "        # 检查文件是否存在\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"文件 {file_path} 不存在\")\n",
    "\n",
    "        # 加载音频文件并重采样到16kHz\n",
    "        waveform, sampling_rate = librosa.load(file_path, sr=16000)\n",
    "\n",
    "        # 提取音频特征\n",
    "        audio_feature = extract_audio_features(waveform, _model, feature_extractor)\n",
    "\n",
    "        # 转录音频文本\n",
    "        if language == \"English\":\n",
    "            transcription = transcribe_audio(waveform, model_english, processor_english)\n",
    "        else:\n",
    "            transcription = transcribe_audio(waveform, model_chinese, processor_chinese)\n",
    "        \n",
    "        if self.count < 3:\n",
    "            self.count += 1\n",
    "            print(file_name, \" \", language)\n",
    "            print(\"语音转文字结果:\", transcription)\n",
    "\n",
    "        # 提取文本特征\n",
    "        text_feature = extract_text_features(transcription, tokenizer, bert_model)\n",
    "\n",
    "        # 将音频特征和文本特征填充到统一大小\n",
    "        audio_feature = self.pad_or_truncate_audio(audio_feature, 16384)\n",
    "\n",
    "        # print(audio_feature.shape, text_feature.shape)\n",
    "\n",
    "        label = 1 if story_type == \"True Story\" else 0\n",
    "\n",
    "        return audio_feature, text_feature, label\n",
    "    \n",
    "    def pad_or_truncate_audio(self, audio_feature, target_length):\n",
    "        \"\"\"\n",
    "        对音频特征进行填充或裁剪，确保其长度一致。\n",
    "        \"\"\"\n",
    "        current_length = audio_feature.shape[-1]\n",
    "        \n",
    "        if current_length < target_length:\n",
    "            # 填充\n",
    "            padding = target_length - current_length\n",
    "            audio_feature = np.pad(audio_feature, ((0, 0), (0, padding)), mode='constant')\n",
    "        elif current_length > target_length:\n",
    "            # 裁剪操作：使用均值池化，按目标长度进行聚合\n",
    "            # 假设audio_feature的形状是 (batch_size, feature_dim)，可以通过在最后一维做池化\n",
    "            step_size = current_length // target_length\n",
    "            pooled_audio = []\n",
    "            for i in range(target_length):\n",
    "                start = i * step_size\n",
    "                end = (i + 1) * step_size\n",
    "                pooled_audio.append(np.mean(audio_feature[:, start:end], axis=1))  # 沿着特征维度求均值\n",
    "            audio_feature = np.stack(pooled_audio, axis=1)  # 将均值结果堆叠在一起\n",
    "\n",
    "        return audio_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集语言和故事类型分布：\n",
      "stratify_col\n",
      "English_True Story         20\n",
      "English_Deceptive Story    20\n",
      "Chinese_True Story         20\n",
      "Chinese_Deceptive Story    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集语言和故事类型分布：\n",
      "stratify_col\n",
      "English_Deceptive Story    5\n",
      "Chinese_Deceptive Story    5\n",
      "Chinese_True Story         5\n",
      "English_True Story         5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['stratify_col'] = df['Language'] + \"_\" + df['Story_type']\n",
    "\n",
    "# 使用train_test_split进行分层抽样\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['stratify_col'], random_state=42)\n",
    "\n",
    "# 打印分层结果\n",
    "print(\"训练集语言和故事类型分布：\")\n",
    "print(train_df['stratify_col'].value_counts())\n",
    "\n",
    "print(\"\\n测试集语言和故事类型分布：\")\n",
    "print(test_df['stratify_col'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00097.wav   Chinese\n",
      "语音转文字结果: 上洲我相望一家顾而怨是<unk>望我大学时期志愿服务时认识的小难骸好号那谁安静动日口温人和的撒录事空计中假达着但难韩一当人均人那间熟悉的愿字时号号正坐在丘陷让你头专注的白农的人一个基目完偶 含林一生他的名字他他系头<unk>了一下随即录出了大大的笑人放向完具非一奔过来爆助了我哥他了生你尼人熟悉的搬快我摸了模的害头发见他比我剂有展高了不手但的双明样惊亦就充满还特有纯真我们坐在院子的意角聊天高送我他最心喜欢上话话还听奋的跑回房间拿出一本画测给我看开话测里面是期些日嫩却深动的化作或的是孤人怨的生呼认着很来猫弥小火吧他又一父话了一个人穿着知人整个<unk>架真阿着他手只人的夫话碾点说这是安是尼我的心头一震<unk>似有温暖我告送他他话棒应该坚持下去号号用力点了点头人你满是期带你奏他经紧拉使<unk>哥应还为再来吧我<unk>叫来看他阵重的轨到定会到时怀来为带上你的王数数意起来看你  李看故而认认不住回看了号战在门口像我会归手杨光死在他小想生一下了额外温暖这一颗我明拜了陪万与怪爱也许就是我们给与他最重要的意样而号好的纯真和勇敢也让我对生活又了更多的噶物\n",
      "00081.wav   English\n",
      "语音转文字结果: IN CALTING WARMTH ITHER WUL A FREEZING WINTER BY THE WIND WAS BLOWI BLOWLING LIKE A KNIFE ACROSS MY FACE I HAD JUST EXPERIENCE THE MAJOR SET BACK AT WARK AND MY MOOD MOOND WAS THE EXTREMELY LOW WORKING ON THE DESERTED STREET I DIDN'T KNOW WHERE I SHOULD GO WHEN I PASSED BY A COFFEE SHOP THE WARM LIGHT THEYARE SIMILAR TO HAVE A E II HAVE AN E IS THE EX THEPLAGU CABOL ATTRACTIN AN I COULDN'T HAL BAT A WORKE THE SHOP WAS FILLED WITH THE RICH AROMA OF COFFEE AND  SON S SMOTHY MUSIC WAS FLOWING IN THE AIR I FOUND A CONER AND SAT DOWN ORDERIN OLERING A COB OF COFFEE TRYING TO CALM MYSELF DOWN JUST THEN A GIRL COME OVER SHE HAD LONG BLACK HAIR AND BRAT IFES WITH A WARM SMILE ON HER FACE HALLOW MAY I SIT HERE SHE PONEAD THO THE SIT OF IT OPA OPOSIT ME IF I WAS A BIT SURPRISE BUT LA STILL NOODED AFTER THE GIRL SAT DOWN WE STARTED CHATTING HER WOICE WAS PRETTY GENTLE AN HER WARTS WERE FALL OF LOVE OF LIFE AND  APOSITIO ATTITUDE SHE SHARED WITH ME HER TRAVELLING PERIENCEES THE GOOD POST SHE HAD RAD AND  THE INTERESTING PEOPLE SHE HAD MAT YE HER NEER NEER NARRITION I SEEMED TO SEE A CALLED FOR WARD A WARD WAYS I'LL TROUBLES AND SATBACK ONLY ENINES BEAUTY AND HOPE BEFORE I KNEW IT I MY MOON MY MOON HAD THE GRADUALLY IMPROVED WHEN WE WERE ABOUT TO LEAVE THE GIRL HAD HANDED ME A PICE OF PAPER WITH A SENTENCE RET ON IT THEREWER ALWAYS BEAT OFF TIMESHENG LIFE BUT PLEASE BELIEVE THAT SOMETHING ONT FOR IS ALL IS ABOUT TO HAPPEN I WASHED HER WORKING AWAY AND MY HEART WAS FALL OF EMOTION SINCE THEN WHEN I WER I IN CONTER DIFFICULTIES AND SAT BAK I I ALWAYS TINK OF SINK OF THAT GIRL AND HER WART SHE IS LIKE A WARM WI WARMRAY OF SUNLIGHT I O MENITIN THE PASS AND TA HAD OF ME IN MY DARKESSE TE MOMENTS THIS CHANCE IN CONTER HAS BECOME AN UNFORGET BOR EXPERIENCE IN MY LIFE IT HAS MADE ME ANS UNDERSTAND THAT EVEN IN THE CODIS WINTER THERE WELL BE WARMTH AS LONGWAY FAIL AND A TIS GAVER OFER HEARTS THERE IS BEAUTY EVERERY IN LIFE\n",
      "00042.wav   Chinese\n",
      "语音转文字结果: 而那是一个充满期待的日子我中于签自需到了美国参加了一常恩别的比赛不仅如此外获得的一个与篮球巨星乐布朗占姆斯建面的机会这一切听起了相绪个梦但是但我战的洛杉矶的斯台普斯中心门前时我几乎不敢相新自己电睛我一及是占姆斯中式审丝从他钢津联盟一个赛季开始我就一直关注的的比赛建争了他从克力弗兰到迈阿密在到回到克里弗兰在到最终加入洛杉级胡人获得多个总关军的规皇力程农过亲眼到他甚至与他面对面交流对果来说简身是巫于伦比农要那天我早造的来到比赛场地攻击中迷曼的星分于仅张的气分胡人对的将对争勇事求民们剧级在门外面新分的讨仑的比赛的预测和球员表现终于作人员但我进入了专门位媒体和被然批加面准备的曲这里可以禁级力更察到球队的准备过程他我走金球员更音式的走郎时突然听到了一争成中的要部生我转身演前着出现的内位从晓就重班的篮球巨行乐布朗战姿他创胡人对的训练服成上拿利评视正走向训练场地虽然到看遣的专专注但当他看到我实被位一效似乎队并不末神们开始逃路篮球也了个了他多然的生活告诉我出来安究场到挑战加庭和社会责战是他人称中最重了的组部分他即到作被民运动员还有是也会面令巨大牙力他使中相信通过团对支持和不限努力一些困难动动国课服无问他在你曼场的职接生涯中什么时候让觉得最美交詹姆次成自鲁判明科为被效着回答我最大交二就是能多肉的家乡克里弗兰电回定个总关军广杯他乘团对分赠的杰果也是我直接生涯中最南望的一颗明德总冠军布止是被了我自己而是被的那些一直支事我的球明和家强的人在短的交流中占姆似对给我了他了身客的影象他的签训专注他对篮球的追爱原员超出我和认识不简身场成的超级剧行场向了他也充满制税和人情位当我与他告别时物感到一种男隐严疫的满足感能过与战姆次战的北大用动员面的面交领或是我人成争最保规的经历之义经刚晚车到向战姆部次战的人物可能一称只份的门义色偶与他的称专注和热情的精神将永远极离我不断追求级的孟象       比赛开始了目作在场边演睛经济经了求上的美一刻占姆斯在场上表现如童平常应样领人精态而在场外的那一颗的真诚和先逊也身神的出动落在操赞\n",
      "训练集特征和标签提取完成。\n",
      "训练集音频特征形状: (80, 16384)\n",
      "训练集文本特征形状: (80, 768)\n",
      "训练集标签形状: (80,)\n",
      "00072.wav   English\n",
      "语音转文字结果: IT WAS IT WAS A TIME I BACK TO TO SOLSAN THEN FOURTEEN ANDHE HAS BEEN YEARS SINCE WE CAME ALTOGETHER WITH MY FAMILY WE GO TO A RENEWIAN ASTE LAKE SI CABIAN AND THEN I REMEMBER THE LIKELESS AROUNDED BY TOWVERING PINES WE HAVE BEEN YEARS TILL REUNION TOGETHER I FELL A MIXTURE OF JOY IN XIETY IN THE AIR WE STILL CONNECTED AS WE ONCE DID AS THE SAN DIPPED BY THE HORIZON CASTING THE GOLDEN HEW OF THE LIKE WE SHARE STARRIES AND MEMORIES AROUND THE FIRE MY CATIN SARA ALWAYS THE JOKE TELLER HAD EVERY ONE IN THE SEACH WITH HER IMPRESSIONS I FELT WORMS OF BELOWING WASH OVER ME LAUGHTER ECHOING INTO THE NIGHTS HET A MISSED THE DRAW I NOTICED MY UNCLE SITTING QUIETLY ON THE EDGE OF THE DARK STARING TO THE WATER HE HAD LAST HIS WIFE A YEAR AGO IN THE THOUGH SHE HE SMILE AT TIMES THE SANUS IN HIS EYES WAS PAPABLE I FELT POUN OF SORROW FOR HIM KNOWING HOW DIFFICULT WAS TO NAVIGATES LEAVES AF GRIEF GET A RINMA CARRIGE I WALKED OVER AND SET BEHIN HIM HE UNCLE TOM WONT YO TALK I ASKED GENTLY HE LOOKED AT ME SURPRISE FLICKING IN HIS IYES WE SPOKE ABOUT SOUNTY MAY SHARING STORIES THAT MADE A SMILING CRY IN THAT MOMENT I FELT CONNECTION DEEPER THE ENDY LAUGHTER SHARE AROUND LIFE LOVIN LOSS IT WAS A REMINDER THE FAMILING BOUNDS CAN HILL EB THE MOST PROFOUND WONTS\n",
      "00044.wav   Chinese\n",
      "语音转文字结果: 二 零一二年我去 了西藏我在拉撒叫 落利及被那里的壮 丽自然景关所吸第一天我参观了布达拉宫宫殿非C常雄伟金币 辉黄 给 我留下 了深 刻 的 印行 我还见到了许多深C川传统服式 的 藏 明他们都非常友 好 我在布达拉宫厅了<unk>油 的解<unk> 了 J讲了西藏 的历史和宗教  夏午我去 了大招似 那里有许多古老 的服 像 和壁 话  我感到一中深深的宁静 和金 位 返服致身于另一个事 境   第二 田我去了那 木错胡虎水非常 清C彻周围都是微额的雪山  我在胡边散部 想受着清新的空气和宁静 的环 境  我还租 了 一艘小C船 滑到 了胡中心水下的景色非常美 丽我能清息的看到水终的鱼和职 物 当 天晚上 我在胡边的 一家小旅 管着下  吕旅管 老 板告诉我当地僧人会在这里举行一些特殊的一世我决定第二 天去参加 第三 田 我进行 了 一次图步旅行 C传 过了高 元上的草 店 和合流 高 园 的景色非 C常状 关 我看到了许多 野生<unk>舞比如藏 灵洋 和藏 野律这次旅行让 我 感到新况神议也对 我 个 人的C成长产生 了巨大 的影 响每次会相起这 次旅行 我都感到非常高兴 和 感击\n",
      "00034.wav   English\n",
      "语音转文字结果: LAST YEAR I PLANNED A TRIP TO PARIES TO A TEND THE OPENING OF A RENOLNED ART GALLERY SHOWCASE IN THE WORK OF MY FAVORIT ARTIST THIS WAS A ONCE IN A LIFETIME OPPORTUNITY AND I HAD BEEN PREPARING FOR MONTHS I HAD CAREFULLY SAVED UP PURCHASED TAKITS WAIL IN ADVANCE AND PLANNED EVERY DETAIL OF THE JOURNEY THE GALLERY WAS GADLED TO OPEN ON A SATURDAY EVENING AND MY FLIGHT WAS SET FOR FRIDAY MORNING TO INGSURE I HAD PLENTY OF TIME ON THE DAY OF THE FLIGHT EVERYTHING STARTED TO GO WRONG I WOKE UP LATER THAN PLANNED BECAUSE I HAD STAYED UP HACKING THE NIGHT BEFOARE I RUSHED THROUGH MY MORNING ROUTIN KEEPING BREAKKEEPING BREAKFAST AND HURRIEDLY COLDED TAXI TO THE AIRPORT IVER TRIED TO NAVIGATE THE MORNING TRAFFIC BUT IT SEEMED EVERY ROAD WAS CONGESTED I NERVOUSLY MY WATCH EVERY FEW MINUTES MY HEART SEKING AS THE MINUTES TAK IT BY IT BY THE TIME WE REACHED THE AIRPOARD I HAD ONLY TWENTY MINUTES LEFT BEFORE TAKE OFF I SPRINTED TO THE CHECKING COUNTER ONLY TO BE TOD THAT THE GATE HAD CLOSED AND MY FLIGHT HAD ALREADY BEGONE BOARDING I SOUED THERE IN DISPLIEF WONTING THE DEPARTUREBOARD AS MY FLIGHT STATES CHANGE TO DEPARTED ITS APPOINTMENT WAS OVERWHELMING I HAD LOOKED FORWARD TO THIS EVENT FOR SO LONG IMAGING MYSELF WALKING THROUGH THE GALLERY SURROUNG ED BIED THE WORKS OF AN ARTIST WHO HAD INSPIRED ME DEEPLY MISSING THE FLIGHT FILLD LIKE I HAD LET THE DOING SLIPPED THROUGH MY FINGERS EMOTIONS TIED SO HID TO SUCH AN EXPERIENCE MAKES ME APPRECIATE THE IMPORTENCE OF PREPARE PREPARATION AND TIMING IS A REMINDER TO NEVER TAKE OPPORTUNITIES FOR GRANTED\n",
      "(20, 16384)\n",
      "测试集特征和标签提取完成。\n",
      "测试集音频特征形状: (20, 16384)\n",
      "测试集文本特征形状: (20, 768)\n",
      "测试集标签形状: (20,)\n"
     ]
    }
   ],
   "source": [
    "# 创建训练集和测试集的DataLoader\n",
    "audio_dir = 'CBU0521DD_stories'\n",
    "train_dataset = AudioDataset(train_df, audio_dir)\n",
    "test_dataset = AudioDataset(test_df, audio_dir)\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 提取训练集特征\n",
    "train_audio_features = []\n",
    "train_text_features = []\n",
    "train_labels = []\n",
    "\n",
    "for audio_features, text_features, label in train_dataloader:\n",
    "    audio_features = audio_features.squeeze()  # 如果是 (batch_size, 1, feature_size)，会去掉1维\n",
    "    text_features = text_features.squeeze()\n",
    "    train_audio_features.append(audio_features.numpy())\n",
    "    train_text_features.append(text_features.numpy())\n",
    "    train_labels.append(label.numpy())\n",
    "\n",
    "train_audio_features_array = np.concatenate(train_audio_features, axis=0)\n",
    "train_text_features_array = np.concatenate(train_text_features, axis=0)\n",
    "train_labels_array = np.concatenate(train_labels, axis=0)\n",
    "\n",
    "print(\"训练集特征和标签提取完成。\")\n",
    "print(\"训练集音频特征形状:\", train_audio_features_array.shape)\n",
    "print(\"训练集文本特征形状:\", train_text_features_array.shape)\n",
    "print(\"训练集标签形状:\", train_labels_array.shape)\n",
    "\n",
    "# 提取测试集特征\n",
    "test_audio_features = []\n",
    "test_text_features = []\n",
    "test_labels = []\n",
    "\n",
    "for audio_features, text_features, label in test_dataloader:\n",
    "    audio_features = audio_features.squeeze()  # 如果是 (batch_size, 1, feature_size)，会去掉1维\n",
    "    text_features = text_features.squeeze()\n",
    "    test_audio_features.append(audio_features.numpy())\n",
    "    test_text_features.append(text_features.numpy())\n",
    "    test_labels.append(label.numpy())\n",
    "\n",
    "# 将特征和标签拼接成 NumPy 数组\n",
    "test_audio_features_array = np.concatenate(test_audio_features, axis=0)\n",
    "test_text_features_array = np.concatenate(test_text_features, axis=0)\n",
    "test_labels_array = np.concatenate(test_labels, axis=0)\n",
    "print(test_audio_features_array.shape)\n",
    "\n",
    "print(\"测试集特征和标签提取完成。\")\n",
    "print(\"测试集音频特征形状:\", test_audio_features_array.shape)\n",
    "print(\"测试集文本特征形状:\", test_text_features_array.shape)\n",
    "print(\"测试集标签形状:\", test_labels_array.shape)\n",
    "\n",
    "# 保存训练集和测试集的特征和标签\n",
    "np.save(\"train_audio_features.npy\", train_audio_features_array)\n",
    "np.save(\"train_text_features.npy\", train_text_features_array)  # 保存文本特征\n",
    "np.save(\"train_labels.npy\", train_labels_array)\n",
    "\n",
    "np.save(\"test_audio_features.npy\", test_audio_features_array)\n",
    "np.save(\"test_text_features.npy\", test_text_features_array)  # 保存文本特征\n",
    "np.save(\"test_labels.npy\", test_labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 定义音频二分类模型\n",
    "class AudioTextClassifier(nn.Module):\n",
    "    def __init__(self, audio_feature_dim, text_feature_dim):\n",
    "        super(AudioTextClassifier, self).__init__()\n",
    "        \n",
    "        # 音频特征的处理：逐步降维到接近文本特征维度\n",
    "        self.audio_fc1 = nn.Linear(audio_feature_dim, 4096)  # 从 260000 降到 100000\n",
    "        self.audio_fc2 = nn.Linear(4096, 1024)   # 从 12000 降到 5000\n",
    "\n",
    "        # 文本特征的处理\n",
    "        self.text_fc = nn.Linear(text_feature_dim, 512)\n",
    "        \n",
    "        # 拼接后的全连接层\n",
    "        self.fc1 = nn.Linear(1536, 2048)  # 拼接后的维度是 text_feature_dim + 1000\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc3 = nn.Linear(512, 1)  # 二分类输出\n",
    "        \n",
    "        # 激活函数和 Dropout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # 防止过拟合\n",
    "        \n",
    "    def forward(self, audio_features, text_features):\n",
    "        # 处理音频特征\n",
    "        audio_x = self.audio_fc1(audio_features)\n",
    "        audio_x = self.relu(audio_x)\n",
    "        audio_x = self.dropout(audio_x)\n",
    "\n",
    "        audio_x = self.audio_fc2(audio_x)\n",
    "        \n",
    "        # 处理文本特征\n",
    "        text_x = self.text_fc(text_features)\n",
    "        \n",
    "        # 拼接音频特征和文本特征\n",
    "        combined_features = torch.cat((audio_x, text_x), dim=1)\n",
    "        \n",
    "        # 经过全连接层\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        # 输出 Sigmoid 激活，用于二分类\n",
    "        return torch.sigmoid(x).squeeze()  # 返回 [0,1] 之间的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "model = AudioTextClassifier(16384, 768).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()  # 二分类交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 转换为 PyTorch 的 Tensor\n",
    "train_audio_features_tensor = torch.tensor(train_audio_features_array, dtype=torch.float32)\n",
    "train_text_features_tensor = torch.tensor(train_text_features_array, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels_array, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "test_audio_features_tensor = torch.tensor(test_audio_features_array, dtype=torch.float32)\n",
    "test_text_features_tensor = torch.tensor(test_text_features_array, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels_array, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.8706, Accuracy: 46.25%\n",
      "Epoch [2/20], Loss: 0.7428, Accuracy: 48.75%\n",
      "Epoch [3/20], Loss: 0.6934, Accuracy: 56.25%\n",
      "Epoch [4/20], Loss: 0.7259, Accuracy: 60.00%\n",
      "Epoch [5/20], Loss: 0.7791, Accuracy: 51.25%\n",
      "Epoch [6/20], Loss: 0.6219, Accuracy: 63.75%\n",
      "Epoch [7/20], Loss: 0.7628, Accuracy: 51.25%\n",
      "Epoch [8/20], Loss: 0.6797, Accuracy: 58.75%\n",
      "Epoch [9/20], Loss: 0.7800, Accuracy: 61.25%\n",
      "Epoch [10/20], Loss: 0.6484, Accuracy: 65.00%\n",
      "Epoch [11/20], Loss: 0.6692, Accuracy: 61.25%\n",
      "Epoch [12/20], Loss: 0.6425, Accuracy: 60.00%\n",
      "Epoch [13/20], Loss: 0.6014, Accuracy: 60.00%\n",
      "Epoch [14/20], Loss: 0.5604, Accuracy: 66.25%\n",
      "Epoch [15/20], Loss: 0.5503, Accuracy: 70.00%\n",
      "Epoch [16/20], Loss: 0.4936, Accuracy: 71.25%\n",
      "Epoch [17/20], Loss: 0.5326, Accuracy: 71.25%\n",
      "Epoch [18/20], Loss: 0.6657, Accuracy: 61.25%\n",
      "Epoch [19/20], Loss: 0.5885, Accuracy: 68.75%\n",
      "Epoch [20/20], Loss: 0.4739, Accuracy: 76.25%\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 20\n",
    "batch_size = 8  # 设定 batch_size\n",
    "\n",
    "train_dataset = TensorDataset(train_audio_features_tensor, train_text_features_tensor, train_labels_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_audio_features_tensor, test_text_features_tensor, test_labels_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for audio_features, text_features, labels in train_dataloader:\n",
    "        audio_features, text_features, labels = audio_features.to(device), text_features.to(device), labels.to(device)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(audio_features, text_features)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算训练准确率\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_dataloader):.4f}, Accuracy: {train_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.00%\n",
      "Test Loss: 1.4555\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.50      0.59        10\n",
      "         1.0       0.62      0.80      0.70        10\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.66      0.65      0.64        20\n",
      "weighted avg       0.66      0.65      0.64        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()  # 进入评估模式\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "predictions = []\n",
    "labels_list = []\n",
    "\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    for audio_features, text_features, labels in test_dataloader:\n",
    "        # 将数据移到设备上\n",
    "        audio_features, text_features, labels = audio_features.to(device), text_features.to(device), labels.to(device)\n",
    "        labels = labels.view(-1)  # 确保标签的形状正确\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(audio_features, text_features)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # 计算预测结果\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # 将预测结果和标签保存在列表中\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "# 计算准确率\n",
    "test_accuracy = 100 * correct / total\n",
    "average_loss = test_loss / len(test_dataloader)\n",
    "\n",
    "# 输出测试准确率和损失\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test Loss: {average_loss:.4f}\")\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels_list, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
